{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs will be saved to: Outputs/2018/k-means/kmeans_100pct_80_20_trial1_k10\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 0. Parameters & Setup\n",
    "# ---------------------------\n",
    "dataset_path    = r\"/Users/rooj/Documents/RP3-Main/RP3-Imp/clean-datasets/2018.csv\"\n",
    "sample_fraction = 1            # 0.5% of data\n",
    "test_size       = 0.2             # train/test split\n",
    "run_name        = \"kmeans_100pct_80_20_trial1_k10\"\n",
    "output_folder   = os.path.join(\"Outputs\", \"2018\", \"k-means\", run_name)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "print(\"Outputs will be saved to:\", output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data shape: (4339650, 26)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 1. Load & Sample Data\n",
    "# ---------------------------\n",
    "data = pd.read_csv(dataset_path, low_memory=False)\n",
    "# Drop any header‑rows misread as data\n",
    "data = data[data['label'] != 'Label']\n",
    "# Sample a fraction\n",
    "data = data.sample(frac=sample_fraction, random_state=42).reset_index(drop=True)\n",
    "print(\"Sampled data shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels mapping: {0: 'Benign', 1: 'DoS attacks-Hulk', 2: 'DDoS attacks-LOIC-HTTP', 3: 'DDOS attack-HOIC', 4: 'DoS attacks-SlowHTTPTest', 5: 'DoS attacks-GoldenEye', 6: 'DoS attacks-Slowloris', 7: 'DDOS attack-LOIC-UDP'}\n",
      "Selected features: ['Dst Port', 'protocol', 'Flow Duration', 'Flow Duration_rolling_mean', 'Flow Duration_rolling_std', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Max', 'Fwd IAT Min', 'SYN Flag Cnt', 'pkts_ratio', 'byte_per_duration', 'entropy_pkt_len', 'Subflow Fwd Byts', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min']\n",
      "Count: 24\n",
      "Data after dropna: (4339650, 24)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 2. Encode Labels\n",
    "# ---------------------------\n",
    "data['label'], uniques = pd.factorize(data['label'])\n",
    "label_names = {i: lab for i, lab in enumerate(uniques)}\n",
    "print(\"Encoded labels mapping:\", label_names)\n",
    "\n",
    "#----------------------------\n",
    "# 3. Select Numeric Features & Clean (drop timestamp)\n",
    "# First, if timestamp is present and numeric, drop it:\n",
    "if 'timestamp' in data.columns:\n",
    "    data = data.drop(columns=['timestamp'])\n",
    "\n",
    "# Now pick up all remaining numeric cols except the label\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols.remove('label')\n",
    "selected_features = numeric_cols\n",
    "print(\"Selected features:\", selected_features)\n",
    "print(\"Count:\", len(selected_features))  # should be 24\n",
    "\n",
    "# Drop any rows with missing values in those features or label\n",
    "df_clean = data[selected_features + ['label']].dropna().reset_index(drop=True)\n",
    "X = df_clean[selected_features].values\n",
    "y = df_clean['label'].values\n",
    "print(\"Data after dropna:\", X.shape)  # should be (n_samples, 24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Outputs/2018/k-means/kmeans_100pct_80_20_trial1_k10/pca_model.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 4. Standardize & PCA\n",
    "# ---------------------------\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "joblib.dump(scaler, os.path.join(output_folder, \"scaler.pkl\"))\n",
    "\n",
    "pca = PCA(n_components=8).fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "joblib.dump(pca, os.path.join(output_folder, \"pca_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3471720, Test size: 867930\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 5. Train/Test Split\n",
    "# ---------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y,\n",
    "    test_size=test_size,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "print(f\"Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting KMeans with k=10...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Outputs/2018/k-means/kmeans_100pct_80_20_trial1_k10/kmeans_k10.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 6. Fit KMeans (\n",
    "# ---------------------------\n",
    "fixed_k =10  # Set a fixed number of clusters for KMeans\n",
    "print(f\"Fitting KMeans with k={fixed_k}...\")\n",
    "\n",
    "km = KMeans(\n",
    "    n_clusters=fixed_k,\n",
    "    init='k-means++',\n",
    "    n_init=1,\n",
    "    random_state=42\n",
    ").fit(X_train)\n",
    "joblib.dump(km, os.path.join(output_folder, f\"kmeans_k{fixed_k}.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train cluster composition (% of true labels per cluster):\n",
      " true       Benign  DoS attacks-Hulk  DDoS attacks-LOIC-HTTP  DDOS attack-HOIC  \\\n",
      "cluster                                                                         \n",
      "0        0.388184          0.000009                0.586079          0.000000   \n",
      "1        0.700859          0.033345                0.000000          0.224972   \n",
      "2        0.999996          0.000000                0.000000          0.000000   \n",
      "3        0.999737          0.000000                0.000103          0.000000   \n",
      "4        0.002120          0.000000                0.279809          0.000000   \n",
      "5        0.013238          0.000000                0.940327          0.000000   \n",
      "6        1.000000          0.000000                0.000000          0.000000   \n",
      "7        0.022134          0.388344                0.000000          0.465034   \n",
      "8        0.992555          0.000000                0.000000          0.000000   \n",
      "9        0.967558          0.005800                0.000351          0.000000   \n",
      "\n",
      "true     DoS attacks-SlowHTTPTest  DoS attacks-GoldenEye  \\\n",
      "cluster                                                    \n",
      "0                        0.000022               0.021361   \n",
      "1                        0.000000               0.040702   \n",
      "2                        0.000000               0.000004   \n",
      "3                        0.000000               0.000001   \n",
      "4                        0.000000               0.000000   \n",
      "5                        0.000000               0.029362   \n",
      "6                        0.000000               0.000000   \n",
      "7                        0.124486               0.000000   \n",
      "8                        0.000000               0.000000   \n",
      "9                        0.000000               0.000663   \n",
      "\n",
      "true     DoS attacks-Slowloris  DDOS attack-LOIC-UDP  \n",
      "cluster                                               \n",
      "0                     0.004345              0.000000  \n",
      "1                     0.000122              0.000000  \n",
      "2                     0.000000              0.000000  \n",
      "3                     0.000125              0.000035  \n",
      "4                     0.000000              0.718071  \n",
      "5                     0.017073              0.000000  \n",
      "6                     0.000000              0.000000  \n",
      "7                     0.000000              0.000002  \n",
      "8                     0.007445              0.000000  \n",
      "9                     0.025617              0.000011  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 7. Cluster → Majority‐Label Mapping & Train Composition\n",
    "# ---------------------------\n",
    "train_clusters = km.labels_\n",
    "cluster_map = {\n",
    "    c: int(np.bincount(y_train[train_clusters == c]).argmax())\n",
    "    for c in np.unique(train_clusters)\n",
    "}\n",
    "\n",
    "# Train cluster composition\n",
    "df_train_comp = pd.DataFrame({'true': y_train, 'cluster': train_clusters})\n",
    "train_comp = (\n",
    "    df_train_comp\n",
    "    .groupby('cluster')['true']\n",
    "    .value_counts(normalize=True)\n",
    "    .unstack(fill_value=0)\n",
    "    .rename(columns=lambda i: label_names[i])\n",
    ")\n",
    "print(\"\\nTrain cluster composition (% of true labels per cluster):\\n\", train_comp)\n",
    "\n",
    "# ---------------------------\n",
    "# 8. Predict on Test\n",
    "# ---------------------------\n",
    "test_clusters = km.predict(X_test)\n",
    "y_pred = np.array([cluster_map[c] for c in test_clusters])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 9. Accuracy, Report & Test Composition\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Classification Report\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 9. Accuracy, Report & Test Composition\n",
    "# ---------------------------\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "class_names = [label_names[i] for i in range(len(label_names))]\n",
    "report = classification_report(\n",
    "    y_test, y_pred,\n",
    "    labels=list(cluster_map.values()),\n",
    "    target_names=class_names,\n",
    "    zero_division=0,\n",
    "    digits=4\n",
    ")\n",
    "print(\"\\n=== Classification Report ===\\n\", report)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(\n",
    "    y_test, y_pred,\n",
    "    labels=list(cluster_map.values())\n",
    ")\n",
    "print(\"=== Confusion Matrix ===\\n\", cm)\n",
    "\n",
    "# Compute and print test cluster composition\n",
    "df_test_comp = pd.DataFrame({'true': y_test, 'cluster': test_clusters})\n",
    "test_comp = (\n",
    "    df_test_comp\n",
    "    .groupby('cluster')['true']\n",
    "    .value_counts(normalize=True)\n",
    "    .unstack(fill_value=0)\n",
    "    .rename(columns=lambda i: label_names[i])\n",
    ")\n",
    "print(\"\\nTest cluster composition (% of true labels per cluster):\\n\", test_comp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 10. Plot & Save Confusion Matrix\n",
    "# ---------------------------\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "im = ax.imshow(cm, cmap=plt.cm.Blues, interpolation='nearest')\n",
    "ax.set_xticks(np.arange(len(class_names)))\n",
    "ax.set_yticks(np.arange(len(class_names)))\n",
    "ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "ax.set_yticklabels(class_names)\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "ax.set_xlabel(\"Predicted label\")\n",
    "ax.set_ylabel(\"True label\")\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "fig.tight_layout()\n",
    "\n",
    "cm_path = os.path.join(output_folder, \"confusion_matrix.png\")\n",
    "plt.savefig(cm_path, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 11. AUC-ROC\n",
    "# ---------------------------\n",
    "n_classes = len(class_names)\n",
    "y_test_bin = label_binarize(y_test, classes=list(range(n_classes)))\n",
    "y_score = np.zeros((len(y_pred), n_classes))\n",
    "for idx, p in enumerate(y_pred):\n",
    "    y_score[idx, p] = 1\n",
    "auc = roc_auc_score(y_test_bin, y_score, average=\"weighted\", multi_class=\"ovr\")\n",
    "print(f\"AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 12. Save All Metrics to TXT\n",
    "# ---------------------------\n",
    "metrics_txt = os.path.join(output_folder, \"test_evaluation_metrics.txt\")\n",
    "with open(metrics_txt, \"w\") as f:\n",
    "    f.write(f\"Test Accuracy: {acc:.4f}\\n\\n\")\n",
    "    f.write(\"=== Classification Report ===\\n\")\n",
    "    f.write(report + \"\\n\")\n",
    "    f.write(\"=== Confusion Matrix ===\\n\")\n",
    "    f.write(str(cm) + \"\\n\\n\")\n",
    "    f.write(f\"AUC-ROC: {auc:.4f}\\n\")\n",
    "\n",
    "# Save cluster compositions\n",
    "train_comp.to_csv(os.path.join(output_folder, \"train_cluster_composition.csv\"))\n",
    "test_comp.to_csv(os.path.join(output_folder, \"test_cluster_composition.csv\"))\n",
    "\n",
    "print(\"All evaluation metrics and compositions saved to:\", output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
